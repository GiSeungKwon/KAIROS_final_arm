import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
import pandas as pd
import numpy as np
import os
import cv2
import time
from tqdm import tqdm
import warnings

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ ì„¤ì •
warnings.filterwarnings("ignore")

# ----------------------------------------------------
# 0. í™˜ê²½ ì„¤ì • (Configuration)
# ----------------------------------------------------
# ë°ì´í„° ê²½ë¡œ ì„¤ì •
DATA_DIR = "../data/Arm/masked_output"
CSV_FILE = os.path.join(DATA_DIR, "masked_joint_labels.csv")
# Min/Max í†µê³„ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ìƒˆë¡œ ì¶”ê°€)
STATS_PATH = os.path.join(DATA_DIR, "joint_stats.csv")

# í•™ìŠµ ì„¤ì •
EPOCHS = 100
BATCH_SIZE = 32
LEARNING_RATE = 1e-4

# ëª¨ë¸ ì €ì¥ ê²½ë¡œ
MODEL_SAVE_DIR = "models"
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)
CHECKPOINT_INTERVAL = 5 # 5 epochë§ˆë‹¤ ëª¨ë¸ ì €ì¥

# CUDA ì„¤ì •
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"âœ… ì‚¬ìš© ì¥ì¹˜: {DEVICE}")

# ----------------------------------------------------
# A. ë°ì´í„°ì…‹ í†µê³„ ìƒì„± í•¨ìˆ˜
# ----------------------------------------------------
def create_joint_stats(csv_path, stats_path, label_cols=['J1', 'J2', 'J3', 'J4', 'J5', 'J6']):
    """
    ê´€ì ˆ ê°ë„ ë°ì´í„°ì˜ Min/Max í†µê³„ë¥¼ ê³„ì‚°í•˜ê³  CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    if os.path.exists(stats_path):
        print(f"âœ”ï¸ í†µê³„ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {stats_path}")
        return

    print(f"â³ í†µê³„ íŒŒì¼ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
    try:
        df = pd.read_csv(csv_path)
        stats = df[label_cols].agg(['min', 'max']).T
        stats.columns = ['Min', 'Max'] # ì—´ ì´ë¦„ì„ 'Min', 'Max'ë¡œ ì„¤ì •
        
        # íŒŒì¼ ì €ì¥
        stats.to_csv(stats_path)
        print(f"ğŸ‰ í†µê³„ íŒŒì¼ ìƒì„± ì™„ë£Œ: {stats_path}")
    except Exception as e:
        print(f"âŒ í†µê³„ íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit()


# ----------------------------------------------------
# 1. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (MyCobotDataset) - ì •ê·œí™” ë¡œì§ ìˆ˜ì •
# ----------------------------------------------------
class MyCobotDataset(Dataset):
    """
    ì´ë¯¸ì§€ì™€ 6ê°œì˜ ê´€ì ˆ ê°ë„(J1-J6)ë¥¼ ë¡œë“œí•˜ê³  ì •ê·œí™”í•˜ëŠ” PyTorch Dataset í´ë˜ìŠ¤
    (ë°ì´í„° í†µê³„ ê¸°ë°˜ ì •ê·œí™” ì ìš©)
    """
    def __init__(self, csv_file, root_dir, stats_path, transform=None):
        self.data_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        self.label_cols = ['J1', 'J2', 'J3', 'J4', 'J5', 'J6']
        
        # Min/Max í†µê³„ ë¡œë“œ
        self.stats = pd.read_csv(stats_path, index_col=0)
        self.joint_min = torch.from_numpy(self.stats['Min'].values.astype(np.float32))
        self.joint_max = torch.from_numpy(self.stats['Max'].values.astype(np.float32))
        self.joint_range = self.joint_max - self.joint_min # range ë¯¸ë¦¬ ê³„ì‚°

    def __len__(self):
        return len(self.data_frame)

    def normalize_joints(self, joint_tensor):
        """Min-Max Scaling to [-1, 1]"""
        # ê³µì‹: y = (X_raw - Min) / (Max - Min) * 2 - 1
        # tensor.numpy()ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë°”ë¡œ tensor ì—°ì‚° ìˆ˜í–‰
        return 2.0 * ((joint_tensor - self.joint_min) / self.joint_range) - 1.0

    @staticmethod
    def denormalize_joints(joint_tensor_norm, joint_min, joint_max):
        """Denormalization from [-1, 1] to original range"""
        # ê³µì‹: X_raw = (X_norm + 1) / 2 * (Max - Min) + Min
        joint_range = joint_max - joint_min
        return (joint_tensor_norm + 1.0) / 2.0 * joint_range + joint_min
        
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        # 1. ì´ë¯¸ì§€ ë¡œë“œ
        # ì²« ë²ˆì§¸ ì—´ì´ Image_Fileì´ë¼ê³  ê°€ì •
        img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0]) 
        image = cv2.imread(img_name)
        
        if image is None:
            # íŒŒì¼ì„ ì°¾ì§€ ëª»í•˜ë©´ í…ì„œì™€ í”Œë˜ê·¸ ë°˜í™˜
            print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_name}. 0 í…ì„œ ë°˜í™˜.")
            # ResNetì˜ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ë¹ˆ í…ì„œ ë°˜í™˜
            return torch.zeros(3, 224, 224), torch.zeros(len(self.label_cols)), True

        # OpenCVëŠ” BGRì´ë¯€ë¡œ RGBë¡œ ë³€í™˜
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # 2. Joint Angle ë¡œë“œ ë° ì •ê·œí™”
        angles = self.data_frame.iloc[idx][self.label_cols].values.astype(np.float32)
        angles_tensor = torch.from_numpy(angles)
        
        # ë°ì´í„°ì…‹ í†µê³„ë¥¼ ì‚¬ìš©í•œ ì •ê·œí™” ì ìš©
        normalized_angles = self.normalize_joints(angles_tensor)
        
        # 3. ì´ë¯¸ì§€ ë³€í™˜ (Transformation)
        if self.transform:
            image = self.transform(image)
        
        # ì„¸ ë²ˆì§¸ ë°˜í™˜ ê°’(True/False)ì€ ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ í”Œë˜ê·¸ (í•™ìŠµ ì½”ë“œì˜ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ False ê³ ì •)
        return image, normalized_angles, False


# ----------------------------------------------------
# 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ë°ì´í„° ë¡œë” (Preprocessing & DataLoader)
# ----------------------------------------------------
# ResNet ëª¨ë¸ì— ì í•©í•œ í‘œì¤€ ì „ì²˜ë¦¬ (224x224 ë¦¬ì‚¬ì´ì¦ˆ ë° ImageNet í‘œì¤€ ì •ê·œí™”)
transform = transforms.Compose([
    transforms.ToPILImage(), # numpy arrayë¥¼ PIL Imageë¡œ ë³€í™˜
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    # ImageNet í‰ê·  ë° í‘œì¤€í¸ì°¨ ì‚¬ìš©
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ----------------------------------------------------
# 3. ëª¨ë¸ ì •ì˜ (ResNet-50 Regression Model)
# ----------------------------------------------------
# ì‚¬ì „ í•™ìŠµëœ ResNet-50 ë¡œë“œ
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)

# ìµœì¢… Fully Connected Layerë¥¼ íšŒê·€ ë¬¸ì œì— ë§ê²Œ ìˆ˜ì •
# ì…ë ¥ íŠ¹ì§• ìˆ˜ (ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„, ResNet-50ì€ 2048)
num_ftrs = model.fc.in_features 

# ì¶œë ¥: Joint 1 ~ Joint 6 (ì´ 6ê°œ)
model.fc = nn.Linear(num_ftrs, 6) 

# ëª¨ë¸ì„ GPUë¡œ ì´ë™
model = model.to(DEVICE)


# ----------------------------------------------------
# 4. í•™ìŠµ ì„¤ì • ë° í•¨ìˆ˜ (Training Setup)
# ----------------------------------------------------
# íšŒê·€ ë¬¸ì œì´ë¯€ë¡œ í‰ê·  ì œê³± ì˜¤ì°¨(MSE)ë¥¼ ì†ì‹¤ í•¨ìˆ˜ë¡œ ì‚¬ìš©
criterion = nn.MSELoss() 
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

def train_model():
    # ----------------------------------------------------
    # ë°ì´í„°ì…‹ í†µê³„ ë¡œë“œ ë° DataLoader ìƒì„±
    # ----------------------------------------------------
    # A-1. Min/Max í†µê³„ íŒŒì¼ í™•ì¸ ë° ìƒì„±
    create_joint_stats(CSV_FILE, STATS_PATH)
    
    # A-2. Dataset ë¡œë“œ ì‹œ í†µê³„ íŒŒì¼ ê²½ë¡œ ì „ë‹¬
    full_dataset = MyCobotDataset(csv_file=CSV_FILE, root_dir=DATA_DIR, stats_path=STATS_PATH, transform=transform)
    
    # ì •ê·œí™”/ì—­ì •ê·œí™”ì— ì‚¬ìš©í•  Min/Max ê°’ ì €ì¥ (GPUë¡œ ì „ì†¡)
    # í•™ìŠµ ë£¨í”„ ì™¸ë¶€ì—ì„œ í•œ ë²ˆë§Œ ì„¤ì •
    J_MIN_TENSOR = full_dataset.joint_min.to(DEVICE)
    J_MAX_TENSOR = full_dataset.joint_max.to(DEVICE)
    
    # A-3. ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° í•„í„°ë§ (ë¶ˆí•„ìš”í•œ ì—ëŸ¬ ë°©ì§€)
    valid_indices = [i for i in range(len(full_dataset)) if not full_dataset[i][2]]
    valid_dataset = torch.utils.data.Subset(full_dataset, valid_indices)

    if len(valid_dataset) == 0:
        print("Error: ìœ íš¨í•œ ë°ì´í„° ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ê²½ë¡œ, CSV, STATS íŒŒì¼ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        return

    dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    print(f"Total Valid Samples: {len(valid_dataset)}")
    
    # ----------------------------------------------------
    # í•™ìŠµ ë£¨í”„ ì‹œì‘
    # ----------------------------------------------------
    best_loss = float('inf')
    
    for epoch in range(1, EPOCHS + 1):
        # í›ˆë ¨ ë‹¨ê³„
        model.train()
        running_loss_norm = 0.0
        
        # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ë¥  í‘œì‹œ
        pbar = tqdm(dataloader, desc=f"Epoch {epoch}/{EPOCHS} [Train]", unit="batch")
        
        for inputs, labels_norm, _ in pbar:
            inputs = inputs.to(DEVICE)
            # labels_normì€ ì´ë¯¸ Datasetì—ì„œ ì •ê·œí™”ë˜ì–´ [-1, 1] ë²”ìœ„
            labels_norm = labels_norm.to(DEVICE).float()
            
            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward + Backward + Optimize
            outputs_norm = model(inputs)
            
            # Loss ê³„ì‚°ì€ ì •ê·œí™”ëœ ê°’ [-1, 1]ìœ¼ë¡œ ìˆ˜í–‰
            loss_norm = criterion(outputs_norm, labels_norm) 
            
            loss_norm.backward()
            optimizer.step()

            running_loss_norm += loss_norm.item() * inputs.size(0)
            pbar.set_postfix({'Loss (Norm)': loss_norm.item()})

        epoch_loss_norm = running_loss_norm / len(valid_dataset)
        
        # ì—­ì •ê·œí™”ëœ Loss ê³„ì‚° (ì‹¤ì œ ê°ë„ ì˜¤ì°¨ RMSE ì¶”ì •)
        # ì—­ì •ê·œí™”ëœ ì¶œë ¥ ë° ë¼ë²¨ì„ ê³„ì‚°
        outputs_denorm = full_dataset.denormalize_joints(outputs_norm, J_MIN_TENSOR, J_MAX_TENSOR)
        labels_denorm = full_dataset.denormalize_joints(labels_norm, J_MIN_TENSOR, J_MAX_TENSOR)
        
        # ì‹¤ì œ ê°ë„ ë‹¨ìœ„ë¡œ MSE Loss ê³„ì‚°
        loss_denorm = criterion(outputs_denorm, labels_denorm).item() 
        avg_angle_error = np.sqrt(loss_denorm / 6) # 6ê°œ ê´€ì ˆ í‰ê·  ê°ë„ ì˜¤ì°¨ (RMSE)
        
        print(f"\n[Epoch {epoch}/{EPOCHS}] Average Loss (Norm): {epoch_loss_norm:.6f} | Avg. Joint Error (RMSE): {avg_angle_error:.2f} deg")
        
        # 5. ëª¨ë¸ ì €ì¥ ë¡œì§
        
        # 5-1. Best Model ì €ì¥ (ì •ê·œí™”ëœ Loss ê¸°ì¤€)
        if epoch_loss_norm < best_loss:
            best_loss = epoch_loss_norm
            best_model_path = os.path.join(MODEL_SAVE_DIR, "best_model.pth")
            torch.save(model.state_dict(), best_model_path)
            print(f"âœ¨ Best Model ì €ì¥ë¨! Loss (Norm): {best_loss:.6f}")

        # 5-2. Checkpoint (5 Epoch)ë§ˆë‹¤ ì €ì¥
        if epoch % CHECKPOINT_INTERVAL == 0:
            checkpoint_path = os.path.join(MODEL_SAVE_DIR, f"checkpoint_epoch_{epoch}.pth")
            torch.save(model.state_dict(), checkpoint_path)
            print(f"ğŸ’¾ Checkpoint ì €ì¥ë¨: {checkpoint_path}")

    print("\n\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    print(f"ìµœì¢… Best Loss (Norm): {best_loss:.6f}")


if __name__ == "__main__":
    train_model()