import torch
import torch.nn as nn
from torchvision import models, transforms
import pandas as pd
import numpy as np
import os
import cv2
import time
import sys
from pymycobot.mycobot import MyCobot

# ----------------------------------------------------
# 0. í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜ (Configuration & Constants)
# ----------------------------------------------------
# A. íŒŒì¼ ê²½ë¡œ ë° ì„¤ì •
DATA_DIR = "../data/Arm/masked_output" # stats.csv ê²½ë¡œë¥¼ í¬í•¨
STATS_PATH = os.path.join(DATA_DIR, "joint_stats.csv")
MODEL_SAVE_PATH = "models/checkpoint_epoch_15.pth" 
CAMERA_INDEX = 0 # ë¡œë´‡ íŒ”ì— ì—°ê²°ëœ ì¹´ë©”ë¼ì˜ ì¸ë±ìŠ¤

# B. ROI ë° HSV ì„¤ì • (í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ)
# í•™ìŠµ ì „ì²˜ë¦¬ ì½”ë“œì— ì œê³µëœ ê°’ìœ¼ë¡œ ìˆ˜ì • (ë‹¨, ì›ë˜ ì½”ë“œì—ëŠ” V_LOW=0, V_HIGH=255)
# **ì£¼ì˜: í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ì •í™•í•œ HSV ë²”ìœ„ë¥¼ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.**
# (ì œê³µëœ ì „ì²˜ë¦¬ ì½”ë“œëŠ” V_LOW=0, V_HIGH=255ë¥¼ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ ì´ ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.)
H_LOW, S_LOW, V_LOW = 0, 0, 0
H_HIGH, S_HIGH, V_HIGH = 179, 255, 240
HSV_LOW = np.array([H_LOW, S_LOW, V_LOW])
HSV_HIGH = np.array([H_HIGH, S_HIGH, V_HIGH])

# ìš”ì²­í•˜ì‹  ROI ì„¤ì • ì ìš©
ROI_START = (30, 30) # (x_min, y_min)
ROI_END = (430, 430) # (x_max, y_max) 
TARGET_IMAGE_SIZE = (224, 224) # ResNet ì…ë ¥ í¬ê¸°

# C. MyCobot ì œì–´ ì„¤ì • (ì‚¬ìš©ì ì½”ë“œ ì°¸ì¡°)
PORT = "COM3"
BAUD = 115200
MOVEMENT_SPEED = 30
INTERMEDIATE_POSE_ANGLES = [-17.2, 30.49, 4.48, 53.08, -90.87, -85.86]
SEQUENTIAL_MOVE_DELAY = 1 
GRIPPER_OPEN_VALUE = 55 
GRIPPER_SPEED = 20

# D. PyTorch ì„¤ì •
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
NUM_JOINTS = 6


# ----------------------------------------------------
# 1. ëª¨ë¸ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜
# ----------------------------------------------------

# A. ResNet ëª¨ë¸ ì •ì˜ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼)
class JointPredictor(nn.Module):
    def __init__(self, num_joints=6):
        super(JointPredictor, self).__init__()
        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        num_ftrs = self.resnet.fc.in_features
        self.resnet.fc = nn.Linear(num_ftrs, num_joints) 

    def forward(self, x):
        return self.resnet(x)

# B. ì •ê·œí™”/ì—­ì •ê·œí™” ìœ í‹¸ë¦¬í‹° (í•™ìŠµ ì½”ë“œì™€ ë™ì¼)
def denormalize_joints(joint_tensor_norm, joint_min, joint_max):
    """Denormalization from [-1, 1] to original range"""
    joint_range = joint_max - joint_min
    return (joint_tensor_norm + 1.0) / 2.0 * joint_range + joint_min

# C. í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
transform = transforms.Compose([
    transforms.ToPILImage(), # numpy arrayë¥¼ PIL Imageë¡œ ë³€í™˜
    transforms.Resize(TARGET_IMAGE_SIZE),
    transforms.ToTensor(),
    # ImageNet í‰ê·  ë° í‘œì¤€í¸ì°¨ ì‚¬ìš©
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# D. ROI ë° HSV ì „ì²˜ë¦¬ í•¨ìˆ˜ (ì‚¬ìš©ì ì½”ë“œ ê¸°ë°˜)
def apply_roi_and_hsv_masking(image, roi_start, roi_end, hsv_low, hsv_high):
    """
    ì›ë³¸ ì´ë¯¸ì§€ì— ROI ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•˜ê³ , ROI ì˜ì—­ ë‚´ì—ì„œ HSV ë§ˆìŠ¤í‚¹ì„ ì ìš©í•˜ì—¬ 
    ìµœì¢… ë°”ì´ë„ˆë¦¬ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # 1. ROI ì ìš©: ROI ì™¸ë¶€ë¥¼ ê²€ì€ìƒ‰ìœ¼ë¡œ ë§Œë“¤ ë§ˆìŠ¤í¬ ìƒì„±
    # í•™ìŠµëœ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ê°€ 'ë°°ê²½ ê²€ì€ìƒ‰, ë¬¼ì²´ í°ìƒ‰' ë°”ì´ë„ˆë¦¬ì˜€ìœ¼ë¯€ë¡œ ì´ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
    x_min, y_min = roi_start
    x_max, y_max = roi_end
    
    masked_image_roi = image.copy()
    
    # 2. HSV ë³€í™˜ ë° ë§ˆìŠ¤í‚¹
    # ROI ì™¸ë¶€ë¥¼ ê²€ì€ìƒ‰ìœ¼ë¡œ ì„¤ì • (ê²€ì€ìƒ‰ í”½ì…€ì€ HSV ë³€í™˜ í›„ì—ë„ ë§ˆìŠ¤í¬ì— í¬í•¨ë˜ì§€ ì•ŠìŒ)
    # ROI ì™¸ë¶€ë¥¼ ë¨¼ì € ê²€ì€ìƒ‰(0, 0, 0)ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
    masked_image_roi[:y_min, :] = 0 # ìƒë‹¨
    masked_image_roi[y_max:, :] = 0 # í•˜ë‹¨
    masked_image_roi[:, :x_min] = 0 # ì™¼ìª½
    masked_image_roi[:, x_max:] = 0 # ì˜¤ë¥¸ìª½
    
    hsv = cv2.cvtColor(masked_image_roi, cv2.COLOR_BGR2HSV)
    
    # HSV ë²”ìœ„ì— ë”°ë¼ ë§ˆìŠ¤í¬ ìƒì„±
    hsv_mask = cv2.inRange(hsv, hsv_low, hsv_high)
    
    # 3. ìµœì¢… ë°”ì´ë„ˆë¦¬ ì´ë¯¸ì§€ ìƒì„±
    final_binary_image = np.zeros_like(image)
    
    # ë§ˆìŠ¤í¬ ì˜ì—­ (ë¬¼ì²´)ë§Œ í°ìƒ‰ (255, 255, 255)ìœ¼ë¡œ ì±„ì›€
    final_binary_image[hsv_mask > 0] = [255, 255, 255]

    return final_binary_image

# ----------------------------------------------------
# 2. ë©”ì¸ ì¶”ë¡  ë° ì œì–´ ë£¨í”„
# ----------------------------------------------------
def main():
    # 1. ëª¨ë¸ ë¡œë“œ ë° í†µê³„ ë¡œë“œ
    try:
        model = JointPredictor(num_joints=NUM_JOINTS).to(DEVICE)
        state_dict = torch.load(MODEL_SAVE_PATH, map_location=DEVICE)
        
        new_state_dict = {}
        for k, v in state_dict.items():
            new_state_dict['resnet.' + k] = v 
        
        model.load_state_dict(new_state_dict) 
        model.eval()
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {MODEL_SAVE_PATH}")
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ ë˜ëŠ” í†µê³„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”.")
        return
    
    try:
        stats = pd.read_csv(STATS_PATH, index_col=0)
        J_MIN_TENSOR = torch.from_numpy(stats['Min'].values.astype(np.float32)).to(DEVICE)
        J_MAX_TENSOR = torch.from_numpy(stats['Max'].values.astype(np.float32)).to(DEVICE)
        print(f"âœ… í†µê³„ ë¡œë“œ ì„±ê³µ: {STATS_PATH}")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: í†µê³„ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨. joint_stats.csvë¥¼ í™•ì¸í•˜ì„¸ìš”. ì˜¤ë¥˜: {e}")
        return

    # 2. MyCobot ì—°ê²°
    try:
        mc = MyCobot(PORT, BAUD)
        mc.power_on() 
        mc.set_gripper_value(GRIPPER_OPEN_VALUE, GRIPPER_SPEED) # ê·¸ë¦¬í¼ ì—´ê¸°
        print(f"ğŸ¤– MyCobot ì—°ê²° ì„±ê³µ: {PORT}. ì¤€ë¹„ ì™„ë£Œ.")
    except Exception as e:
        print(f"âŒ MyCobot ì—°ê²° ì‹¤íŒ¨ ({PORT}): {e}")
        sys.exit(1)

    # 3. ì¹´ë©”ë¼ ì—°ê²°
    cap = cv2.VideoCapture(CAMERA_INDEX, cv2.CAP_DSHOW)
    if not cap.isOpened():
        print(f"âŒ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ {CAMERA_INDEX}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        mc.close()
        sys.exit(1)
    
    # ì „ì²˜ë¦¬ ì´ë¯¸ì§€ í‘œì‹œ í† ê¸€ ìƒíƒœ
    show_processed_image = False 
    processed_window_open = False

    print("\n--- ğŸ§  MyCobot ì‹¤ì‹œê°„ ì¶”ë¡  ë„êµ¬ ---")
    print("   [i] : í˜„ì¬ í”„ë ˆì„ìœ¼ë¡œ Joint Angle ì¶”ë¡  ë° ë¡œë´‡ ì´ë™")
    print("   [p] : **ëª¨ë¸ ì…ë ¥ ì „** ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í† ê¸€") # ìš”ì²­í•˜ì‹  ê¸°ëŠ¥
    print("   [q] : í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
    print("---------------------------------------")
    
    with torch.no_grad(): # ì¶”ë¡  ì‹œì—ëŠ” gradient ê³„ì‚° ë¶ˆí•„ìš”
        while True:
            ret, frame = cap.read()
            if not ret:
                time.sleep(0.1)
                continue
            
            # 1. ROI ì˜ì—­ ì‹œê°í™”
            cv2.rectangle(frame, ROI_START, ROI_END, (0, 0, 255), 2)
            
            # 2. ì „ì²˜ë¦¬ ì´ë¯¸ì§€ ìƒì„±
            processed_image = apply_roi_and_hsv_masking(frame, ROI_START, ROI_END, HSV_LOW, HSV_HIGH)
            
            # 3. 'p' í‚¤ë¥¼ ëˆŒë €ì„ ë•Œ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ í‘œì‹œ
            if show_processed_image:
                cv2.putText(processed_image, "Processed (p:toggle)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.imshow('Processed Image (Model Input)', processed_image)
                processed_window_open = True # ìœˆë„ìš°ê°€ ì—´ë¦¼
                
            # ğŸ“Œ ìˆ˜ì •ëœ ë¡œì§: ìœˆë„ìš°ê°€ ì—´ë ¤ìˆëŠ”ë° (processed_window_open=True) í‘œì‹œê°€ êº¼ì¡Œì„ ë•Œ (show_processed_image=False) ë‹«ëŠ”ë‹¤.
            elif processed_window_open: 
                cv2.destroyWindow('Processed Image (Model Input)')
                processed_window_open = False # ìœˆë„ìš° ë‹«í˜ ìƒíƒœë¡œ ë³€ê²½

            # 4. ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆì„ í‘œì‹œ
            cv2.imshow('MyCobot Live Camera & Inference Tool', frame)

            # -----------------------------------------
            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            # -----------------------------------------
            key = cv2.waitKey(1) & 0xFF

            # [q]: í”„ë¡œê·¸ë¨ ì¢…ë£Œ
            if key == ord('q'):
                print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # [p]: ì „ì²˜ë¦¬ ì´ë¯¸ì§€ í‘œì‹œ í† ê¸€ (ìš”ì²­ ì‚¬í•­)
            elif key == ord('p'):
                show_processed_image = not show_processed_image
                print(f"\nğŸ’¡ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ í‘œì‹œ: {'ON' if show_processed_image else 'OFF'}")

            # [i]: ì¶”ë¡  ë° ë¡œë´‡ ì´ë™
            elif key == ord('i'):
                print("\nğŸ§  Joint Angle ì¶”ë¡  ì‹œì‘...")
                
                # a) ì „ì²˜ë¦¬ ì´ë¯¸ì§€ -> PyTorch í…ì„œ ë³€í™˜
                # OpenCV (BGR/numpy) -> RGB/numpy -> PIL -> Tensor/Normalize
                try:
                    input_tensor = transform(processed_image) 
                    input_tensor = input_tensor.unsqueeze(0).to(DEVICE) # Batch ì°¨ì› ì¶”ê°€ ë° GPU ì „ì†¡
                except Exception as e:
                    print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    continue

                # b) ëª¨ë¸ ì¶”ë¡  (ì •ê·œí™”ëœ ê°ë„ ì¶œë ¥)
                outputs_norm = model(input_tensor)
                
                # c) ì—­ì •ê·œí™” (ì‹¤ì œ ê°ë„ ë³µì›)
                outputs_denorm = denormalize_joints(outputs_norm, J_MIN_TENSOR, J_MAX_TENSOR)
                
                # d) ê²°ê³¼ ì¶œë ¥ ë° ë¡œë´‡ ì œì–´
                predicted_angles = outputs_denorm.cpu().squeeze(0).numpy().tolist()
                
                # ì†Œìˆ˜ì  í•œ ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì œì–´ ì •í™•ë„ ìœ ì§€ ë° ì¶œë ¥ ê°€ë…ì„± ê°œì„ 
                predicted_angles = [round(a, 1) for a in predicted_angles] 

                print(f"âœ… ì¶”ë¡ ëœ Joint Angles: {predicted_angles}")
                
                # ë¡œë´‡ íŒ” ì´ë™ (ì•ˆì „ì„ ìœ„í•´ ê²½ìœ ì§€ë¥¼ ê²½ìœ )
                print(f"âš™ï¸ ë¡œë´‡ ì´ë™ ì‹œì‘ (ê²½ìœ ì§€ ê²½ìœ  í›„ ìµœì¢…ì§€ {predicted_angles}ë¡œ ì´ë™)")
                
                # 1. ê·¸ë¦¬í¼ ì—´ê¸°
                mc.set_gripper_value(GRIPPER_OPEN_VALUE, GRIPPER_SPEED)
                
                # 2. ì¤‘ê°„ ê²½ìœ  ìì„¸ë¡œ ì´ë™ (ì•ˆì „ì„± í™•ë³´)
                mc.send_angles(INTERMEDIATE_POSE_ANGLES, MOVEMENT_SPEED)
                time.sleep(SEQUENTIAL_MOVE_DELAY)
                
                # 3. ìµœì¢… ì¶”ë¡ ëœ ìì„¸ë¡œ ì´ë™
                mc.send_angles(predicted_angles, MOVEMENT_SPEED)
                time.sleep(SEQUENTIAL_MOVE_DELAY * 2) # ìµœì¢… ì´ë™ í›„ ì¶©ë¶„íˆ ê¸°ë‹¤ë¦¼
                print("âœ… ë¡œë´‡ ì´ë™ ì™„ë£Œ.")
            
            # [0, 1, 2, g, h] í‚¤ëŠ” mycobot_labeling.pyì˜ ê¸°ëŠ¥ê³¼ ë™ì¼í•˜ê²Œ ì‘ë™
            # [0]: ëª¨ë“  Joint ê°ë„ë¥¼ 0ìœ¼ë¡œ ì´ë™
            elif key == ord('0'):
                mc.send_angles(INTERMEDIATE_POSE_ANGLES, MOVEMENT_SPEED)
                time.sleep(SEQUENTIAL_MOVE_DELAY)
                mc.send_angles([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], MOVEMENT_SPEED)
                print("âœ… ZERO_POSE ì´ë™ ì™„ë£Œ.")
                
            # [1]: CONVEYOR_CAPTURE_POSE ì´ë™
            elif key == ord('1'):
                mc.set_gripper_value(GRIPPER_OPEN_VALUE, GRIPPER_SPEED)
                mc.send_angles(INTERMEDIATE_POSE_ANGLES, MOVEMENT_SPEED)
                time.sleep(SEQUENTIAL_MOVE_DELAY)
                mc.send_angles([0, 0, 90, 0, -90, -90], MOVEMENT_SPEED)
                print("âœ… CONVEYOR_CAPTURE_POSE ì´ë™ ì™„ë£Œ.")
                
            # [2]: ROBOTARM_CAPTURE_POSE ì´ë™
            elif key == ord('2'):
                mc.set_gripper_value(GRIPPER_OPEN_VALUE, GRIPPER_SPEED)
                mc.send_angles(INTERMEDIATE_POSE_ANGLES, MOVEMENT_SPEED)
                time.sleep(SEQUENTIAL_MOVE_DELAY)
                mc.send_angles([0, 0, 90, 0, -90, 90], MOVEMENT_SPEED)
                print("âœ… ROBOTARM_CAPTURE_POSE ì´ë™ ì™„ë£Œ.")

            # [g]: ê·¸ë¦¬í¼ ë‹«ê¸°
            elif key == ord('g'):
                mc.set_gripper_value(25, GRIPPER_SPEED) # GRIPPER_CLOSED_VALUEëŠ” 25 (ì°¸ì¡° ì½”ë“œ ê¸°ì¤€)
                time.sleep(1) 
                print("âœ… ê·¸ë¦¬í¼ ë‹«í˜ ì™„ë£Œ.")
                
            # [h]: ê·¸ë¦¬í¼ ì—´ê¸°
            elif key == ord('h'):
                mc.set_gripper_value(GRIPPER_OPEN_VALUE, GRIPPER_SPEED)
                time.sleep(1) 
                print("âœ… ê·¸ë¦¬í¼ ì—´ë¦¼ ì™„ë£Œ.")

    # ì¢…ë£Œ ì •ë¦¬ ì‘ì—…
    cap.release()
    cv2.destroyAllWindows()
    try:
        mc.close()
    except Exception:
        pass
        
if __name__ == "__main__":
    main()